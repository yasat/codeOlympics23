{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oF6IBgFDTAQh",
    "outputId": "7711090e-aaf4-49e7-9cab-87e5ce97ba25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859670\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "response = requests.get('https://www.gutenberg.org/cache/epub/100/pg100.txt')\n",
    "\n",
    "text = response.text\n",
    "\n",
    "para = list()\n",
    "\n",
    "for i in text.split(\"THE SONNETS\")[2].split(\" \"):\n",
    "  para.append(i)\n",
    "\n",
    "shakes = pd.DataFrame(para)\n",
    "\n",
    "shakes.head(100)\n",
    "\n",
    "shakes = shakes.rename(columns={0:\"words\"})\n",
    "\n",
    "shakes['words'] = shakes.words.apply(lambda x: x.strip())\n",
    "\n",
    "shakes = shakes[shakes['words'] != \"\"]\n",
    "\n",
    "shakes['words'] = shakes.words.apply(lambda x: re.sub(\"[0-9]\\r\\n\",\"\", x))\n",
    "shakes['words'] = shakes.words.apply(lambda x: x.replace(\"\\r\", \"\"))\n",
    "shakes['words'] = shakes.words.apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "\n",
    "words = list(shakes.words)\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y07sQFHXd_T6",
    "outputId": "fee81928-1f75-493b-d966-00a0da6ebb26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444985"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 9999999\n",
    "\n",
    "def text_pipeline_spacy(tokens):\n",
    "\n",
    "    p_tokens = []\n",
    "    \n",
    "    #beware!!!! this ate my laptop resources... re\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    for t in doc:\n",
    "        if not t.is_stop and not t.is_punct and not t.is_space:\n",
    "            p_tokens.append(t.lemma_.lower())\n",
    "    return p_tokens\n",
    "\n",
    "words = text_pipeline_spacy(words)\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444785"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = list()\n",
    "stopwords = [\"\", \"a\"]\n",
    "for i in words:\n",
    "#     i = i.replace(\"'\",\"\")\n",
    "#     i = i.replace(\"[\",\"\")\n",
    "#     i = i.replace(\"]\",\"\")\n",
    "#     i = i.replace(\"$\",\"\")\n",
    "    i = re.sub(\"[0-9]\",\"\",i)\n",
    "    i = re.sub(\"[,-\\[\\]'$({})]\",\"\",i)\n",
    "    if(i in stopwords):\n",
    "        continue\n",
    "    processed.append(i)\n",
    "    \n",
    "len(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "jVeWHJqrem7X"
   },
   "outputs": [],
   "source": [
    "def make_vocabulary(corpus):\n",
    "\n",
    "    unique_tokens = sorted(set( t for t in corpus ))\n",
    "    token_to_id = { v:i for i,v in enumerate(unique_tokens)}\n",
    "\n",
    "    return token_to_id\n",
    "\n",
    "vocab = make_vocabulary(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thou', 5343),\n",
       " ('thy', 4138),\n",
       " ('shall', 3558),\n",
       " ('come', 3290),\n",
       " ('thee', 3165),\n",
       " ('good', 3068),\n",
       " ('lord', 3067),\n",
       " ('man', 2852),\n",
       " ('king', 2645),\n",
       " ('love', 2633),\n",
       " ('sir', 2619),\n",
       " ('let', 2204),\n",
       " ('know', 2183),\n",
       " ('enter', 2154),\n",
       " ('like', 1996),\n",
       " ('hath', 1872),\n",
       " ('o', 1834),\n",
       " ('speak', 1433),\n",
       " ('tell', 1362),\n",
       " ('think', 1307),\n",
       " ('time', 1273),\n",
       " ('hear', 1248),\n",
       " ('heart', 1194),\n",
       " ('god', 1162),\n",
       " ('eye', 1153),\n",
       " ('hand', 1123),\n",
       " ('tis', 1085),\n",
       " ('look', 1058),\n",
       " ('father', 1052),\n",
       " ('great', 1049),\n",
       " ('doth', 1013),\n",
       " ('duke', 994),\n",
       " ('leave', 992),\n",
       " ('day', 988),\n",
       " ('bear', 972),\n",
       " ('life', 958),\n",
       " ('lady', 951),\n",
       " ('art', 933),\n",
       " ('friend', 918),\n",
       " ('th', 901),\n",
       " ('master', 881),\n",
       " ('word', 878),\n",
       " ('death', 877),\n",
       " ('fair', 870),\n",
       " ('queen', 836),\n",
       " ('sweet', 835),\n",
       " ('true', 816),\n",
       " ('go', 815),\n",
       " ('son', 811),\n",
       " ('stand', 796),\n",
       " ('find', 774),\n",
       " ('away', 761),\n",
       " ('night', 745),\n",
       " ('heaven', 739),\n",
       " ('live', 738),\n",
       " ('pray', 733),\n",
       " ('fear', 727),\n",
       " ('honour', 723),\n",
       " ('old', 716),\n",
       " ('bring', 713),\n",
       " ('noble', 712),\n",
       " ('lie', 710),\n",
       " ('die', 708),\n",
       " ('thing', 685),\n",
       " ('brother', 685),\n",
       " ('say', 675),\n",
       " ('world', 665),\n",
       " ('well', 660),\n",
       " ('poor', 651),\n",
       " ('blood', 649),\n",
       " ('way', 641),\n",
       " ('give', 636),\n",
       " ('see', 632),\n",
       " ('hold', 631),\n",
       " ('long', 626),\n",
       " ('head', 623),\n",
       " ('grace', 621),\n",
       " ('house', 603),\n",
       " ('prince', 602),\n",
       " ('woman', 600),\n",
       " ('till', 591),\n",
       " ('mean', 584),\n",
       " ('hast', 579),\n",
       " ('gentleman', 574),\n",
       " ('scene', 557),\n",
       " ('send', 547),\n",
       " ('wife', 542),\n",
       " ('exit', 535),\n",
       " ('fall', 533),\n",
       " ('set', 521),\n",
       " ('second', 520),\n",
       " ('soul', 519),\n",
       " ('dead', 518),\n",
       " ('place', 516),\n",
       " ('young', 515),\n",
       " ('little', 511),\n",
       " ('daughter', 508),\n",
       " ('face', 493),\n",
       " ('lose', 491),\n",
       " ('fool', 487)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(processed)\n",
    "\n",
    "counts.most_common(100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
